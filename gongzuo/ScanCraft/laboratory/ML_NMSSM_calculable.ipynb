{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/heyangle/Desktop/ScanCraft/ScanCraft')\n",
    "sys.path.append('C:\\\\Users\\\\vooum\\\\Source\\\\Repos\\\\ScanCraft\\\\ScanCraft')\n",
    "from command.scan import scan\n",
    "from command.NMSSMTools import NMSSMTools\n",
    "mold=scan(method='random')\n",
    "mold.AddScalar('tanB','MINPAR',3,1.,60.)\n",
    "mold.AddScalar('M1','EXTPAR',1  ,20.    ,1000.)\n",
    "mold.AddScalar('M2','EXTPAR'   ,2  ,100.    ,2000.)\n",
    "mold.AddScalar('Atop','EXTPAR'   ,11  ,  -6e3    ,6e3)\n",
    "mold.AddFollower('Abottom','EXTPAR'   ,12,'Atop')\n",
    "mold.AddScalar('Atau','EXTPAR'   ,13  ,  100.      ,2000.)\n",
    "mold.AddFollower('MtauL','EXTPAR'   ,33,'Atau')\n",
    "mold.AddFollower('MtauR','EXTPAR'   ,36,'Atau')\n",
    "mold.AddScalar('MQ3L','EXTPAR'   ,43,\t100.,\t2.e3)\n",
    "mold.AddScalar('MtopR'\t,'EXTPAR'   ,46,\t100.,\t2.e3)\n",
    "mold.AddFollower('MbottomR','EXTPAR'  ,49,'MtopR')\n",
    "mold.AddScalar('Lambda','EXTPAR'  ,61  ,1e-3    ,1. ,prior_distribution='exponential')\n",
    "mold.AddScalar('Kappa','EXTPAR'   ,62 ,1.e-3    ,1. ,prior_distribution='exponential')\n",
    "mold.AddScalar('A_Lambda','EXTPAR' ,63,-3.e3,3.e3)\n",
    "mold.AddScalar('A_kappa','EXTPAR' ,64,-3.e3,3.e3)\n",
    "mold.AddScalar('mu_eff','EXTPAR'  ,65,100.,1500.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete folder record? (y/n) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from command.multi_thread.queue_operation import GenerateQueue,FillQueue\n",
    "from command.multi_thread.MT_NTools import MT_NTools\n",
    "MTN=MT_NTools(threads=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculations begin at Fri Dec  8 22:22:25 2017\n",
      "  threads:\t6\n",
      "  points:\t300\n",
      "  thread-2\truning,      200 points left at Fri Dec  8 22:22:31 2017\n",
      "  thread-1\truning,      100 points left at Fri Dec  8 22:22:37 2017\n",
      "  thread-0\truning,        0 points left at Fri Dec  8 22:22:50 2017\n",
      "All points done. Use 0.010959 hours\n",
      "43 sample recorded in ./Pylon/record\n"
     ]
    }
   ],
   "source": [
    "ore_q=GenerateQueue(mold,lenth=300)\n",
    "# ore_q.qsize()\n",
    "MTN.run(ore_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from command.data_transformer.ArrayToPoint import ArrayToInputQueue\n",
    "# from command.format.data_structure_functions import FlatToList\n",
    "# import numpy\n",
    "# q=ArrayToInputQueue(numpy.random.randn(2,12),mold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=MTN.accepted_list\n",
    "exc=MTN.excluded_list\n",
    "from command.data_transformer.InputListToPandas import InputListToPandas as I2P\n",
    "DF_acc=I2P(acc)\n",
    "DF_exc=I2P(exc)\n",
    "last_name=('input','points','calculable','1=y,0=n')\n",
    "DF_acc[last_name]=1\n",
    "DF_exc[last_name]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "data=numpy.concatenate([DF_acc.values,DF_exc.values],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.save('data3',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "bce=nn.BCEWithLogitsLoss()\n",
    "in_data=Variable(torch.FloatTensor(data[:,:-1]).cuda())\n",
    "target=Variable(torch.FloatTensor(data[:,-1].reshape(300,1)).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.nn.Sequential(\n",
    "    torch.nn.Linear(12,1000),\n",
    "    torch.nn.Linear(1000,10),\n",
    "    torch.nn.Linear(10,1),\n",
    "#     torch.nn.ReLU(),\n",
    "    torch.nn.Sigmoid()\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential (\n",
       "  (0): Linear (12 -> 1000)\n",
       "  (1): Linear (1000 -> 10)\n",
       "  (2): Linear (10 -> 1)\n",
       "  (3): Sigmoid ()\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "-0.1254 -0.0615  0.0552  ...  -0.0587 -0.2114  0.1890\n",
      " 0.2278 -0.0013  0.1871  ...  -0.0116 -0.2759 -0.0507\n",
      " 0.0381  0.0951 -0.0544  ...  -0.2746  0.0301  0.1539\n",
      "          ...             ⋱             ...          \n",
      " 0.2527  0.2605 -0.1895  ...   0.2237 -0.2564  0.2719\n",
      " 0.1371 -0.1007 -0.1792  ...   0.0274  0.1545  0.0189\n",
      " 0.1718  0.2471 -0.2370  ...   0.1389  0.1520  0.1220\n",
      "[torch.cuda.FloatTensor of size 1000x12 (GPU 0)]\n",
      "\n",
      "Parameter containing:\n",
      " 0.1203\n",
      " 0.0593\n",
      " 0.2002\n",
      "   ⋮   \n",
      "-0.1752\n",
      "-0.2745\n",
      "-0.0191\n",
      "[torch.cuda.FloatTensor of size 1000 (GPU 0)]\n",
      "\n",
      "Parameter containing:\n",
      " 3.4886e-03 -1.7333e-02 -1.6789e-02  ...   1.8569e-04 -1.4737e-02  1.7576e-02\n",
      " 3.0980e-02 -1.4178e-02 -4.4440e-03  ...  -1.3244e-02 -1.7774e-03 -9.7443e-03\n",
      "-1.7543e-02 -2.0296e-02 -1.6417e-02  ...  -1.4773e-02 -6.0899e-03 -3.1296e-03\n",
      "                ...                   ⋱                   ...                \n",
      " 2.7893e-02 -2.2324e-02  3.1146e-02  ...   1.4862e-02  7.7109e-03  1.9427e-02\n",
      " 1.4459e-02  1.0515e-02  2.5846e-02  ...   3.8307e-03  1.1883e-02  1.2352e-02\n",
      "-2.3908e-02 -4.1786e-03  1.4141e-02  ...   2.4423e-02 -4.1229e-03  2.4855e-03\n",
      "[torch.cuda.FloatTensor of size 10x1000 (GPU 0)]\n",
      "\n",
      "Parameter containing:\n",
      "1.00000e-02 *\n",
      " -1.4937\n",
      " -1.4270\n",
      " -1.1397\n",
      " -2.7001\n",
      "  2.4873\n",
      "  3.1263\n",
      "  0.2455\n",
      " -0.1867\n",
      "  2.0655\n",
      " -2.1655\n",
      "[torch.cuda.FloatTensor of size 10 (GPU 0)]\n",
      "\n",
      "Parameter containing:\n",
      " 0.0751 -0.1131 -0.1317  0.3101 -0.1212  0.1292 -0.1030  0.2921  0.1962 -0.1780\n",
      "[torch.cuda.FloatTensor of size 1x10 (GPU 0)]\n",
      "\n",
      "Parameter containing:\n",
      "-0.2707\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.2719\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.6204\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       "[torch.cuda.FloatTensor of size 300x1 (GPU 0)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.0133\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce(_,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Variable containing:\n",
      " 1.0133\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "100 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "200 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "300 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "400 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "500 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "600 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "700 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "800 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "900 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "1000 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "1100 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "1200 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "1300 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "1400 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "1500 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "1600 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "1700 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "1800 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "1900 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "2000 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "2100 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "2200 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "2300 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "2400 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "2500 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "2600 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "2700 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "2800 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "2900 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "3000 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "3100 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "3200 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "3300 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "3400 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "3500 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "3600 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "3700 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "3800 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "3900 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "4000 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "4100 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "4200 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "4300 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "4400 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "4500 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "4600 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "4700 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "4800 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "4900 Variable containing:\n",
      " 0.6931\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5000):\n",
    "    out_data=model(in_data)    \n",
    "    loss=bce(out_data,target)\n",
    "    loss.backward()\n",
    "    if i%100==0:print(i,loss)\n",
    "    for param in model.parameters():\n",
    "        param.data-=0.01*param.grad.data\n",
    "    model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "[torch.cuda.FloatTensor of size 300x1 (GPU 0)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "[torch.cuda.FloatTensor of size 300x1 (GPU 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
